# ğŸ§  MCP-MAS: Modular Communication Protocol for Multi-Agent Systems

## ğŸ“Œ é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®æ—¨åœ¨æ„å»ºä¸€ä¸ª**å»ä¸­å¿ƒåŒ–çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿæ¡†æ¶**ï¼Œä½¿æ¯ä¸ªæ™ºèƒ½ä½“å…·å¤‡å®Œæ•´çš„å†³ç­–ä¸æ‰§è¡Œèƒ½åŠ›ï¼Œé€šè¿‡ç»“æ„åŒ–é€šä¿¡åè®®ï¼ˆMCPï¼‰è¿›è¡Œä»»åŠ¡åˆ†é…ã€è‡ªä¸»åè°ƒä¸ååŒæ‰§è¡Œï¼Œæœ€ç»ˆå®ç°å¯æ‰©å±•ã€å¯è§£é‡Šã€ç­–ç•¥å¯æ’æ‹”çš„åˆ†å¸ƒå¼åä½œç³»ç»Ÿã€‚

ç³»ç»Ÿæ”¯æŒå¤šç§ç±»å‹ç­–ç•¥ï¼ˆå¦‚ Rule-basedã€PPOã€Diffusion Policyï¼‰è‡ªç”±æ¥å…¥ï¼Œä»»åŠ¡ç”± Agent è‡ªä¸» claim å¹¶é€šè¿‡é€šä¿¡è¿›è¡Œå†²çªåè°ƒï¼Œæ— éœ€ä¸­å¿ƒè°ƒåº¦æ§åˆ¶ï¼Œå…·å¤‡è‰¯å¥½çš„é€šç”¨æ€§ä¸å·¥ç¨‹å¯è½åœ°æ€§ã€‚

---

## âœ… å½“å‰ç³»ç»Ÿèƒ½åŠ›

- **å¤šæ™ºèƒ½ä½“è¿è¡Œ**ï¼šæ”¯æŒ3ä¸ªAgentåŒæ—¶è¿è¡Œï¼Œå…·å¤‡æ„ŸçŸ¥ã€é€šä¿¡ã€åŠ¨ä½œèƒ½åŠ›ï¼›
- **ä»»åŠ¡ç¯å¢ƒ**ï¼šå¤šä¸ªå¯åˆ†é…ç›®æ ‡ç‚¹ï¼Œä»»åŠ¡éšæœºç”Ÿæˆï¼ŒAgenté€šè¿‡é€šä¿¡å®Œæˆä»»åŠ¡åå•†ï¼›
- **é€šä¿¡åè®® MCP**ï¼š
  - æ”¯æŒä»»åŠ¡ claimã€respondã€retryã€ä¼˜å…ˆçº§åˆ¤æ–­ç­‰ç»“æ„åŒ–æ¶ˆæ¯ï¼›
  - åè®®æ¨¡å—ç‹¬ç«‹å°è£…ï¼Œæ˜“äºç»´æŠ¤ä¸æ‰©å±•ï¼›
- **ç­–ç•¥æ¨¡å—åŒ–**ï¼š
  - æ‰€æœ‰ç­–ç•¥éµå¾ªç»Ÿä¸€æ¥å£ `policy.compute_action(obs, messages)`ï¼›
  - å·²é›†æˆ `NearestTaskPolicy`ã€`RuleBasedPolicy`ã€`DiffusionPolicyWrapperAdapter`ï¼›
- **æ¨¡æ‹Ÿç¯å¢ƒ**ï¼šå½“å‰ä½¿ç”¨ PyBullet å®ç°è½»é‡ä»¿çœŸï¼Œä»»åŠ¡ä¸ Agent å‡æ”¯æŒéšæœºåˆå§‹åŒ–ï¼›
- **ç³»ç»Ÿå¯è§†åŒ–**ï¼šæ”¯æŒ GUI æ¨¡å¼å®æ—¶å¯è§†åŒ–ç³»ç»Ÿè¡Œä¸ºï¼Œä¾¿äºè°ƒè¯•ä¸æ¼”ç¤ºã€‚

---

## ğŸš§ å½“å‰å¼€å‘è¿›åº¦ï¼ˆæˆªè‡³ 2025å¹´6æœˆï¼‰

| æ¨¡å— | çŠ¶æ€ | è¯´æ˜ |
|------|------|------|
| MCPé€šä¿¡ç»“æ„ | âœ… å·²å®Œæˆå°è£…ï¼Œæ”¯æŒå¤šè½®é€šä¿¡ä¸å†²çªåè°ƒ |
| å¤šAgentå¹¶è¡Œ | âœ… æ”¯æŒä¸‰Agentç¨³å®šè¿è¡Œï¼Œè¡Œä¸ºæ­£å¸¸ |
| ç­–ç•¥æ¨¡å—æ¥å£ | âœ… å·²å®ç°ç­–ç•¥ç»Ÿä¸€æ¥å£ä¸å°è£… |
| Diffusion Policyæ¥å…¥ | âœ… å·²å®ŒæˆWrapperï¼Œæ”¯æŒè¿è¡Œstubç­–ç•¥ |
| ç¯å¢ƒæ„å»º | âœ… PyBulletè¿è¡Œç¨³å®šï¼Œä»»åŠ¡ç”Ÿæˆå¯æ§ |
| æ‰§è¡Œè¡Œä¸ºé—®é¢˜æ’æŸ¥ | ğŸŸ¡ å·²å®šä½ç›®æ ‡ä½ç½®æœªæ­£ç¡®è®¾ç½®çš„é—®é¢˜ï¼Œå¾…éªŒè¯ä¿®å¤ |
| é¡¹ç›®ç»“æ„æ–‡æ¡£åŒ– | âœ… æ­£åœ¨å®Œæˆå½“å‰READMEä¸ä»»åŠ¡è§„åˆ’æ•´ç† |

---

## ğŸ“ˆ æœªæ¥é˜¶æ®µè§„åˆ’

### ğŸ”„ é˜¶æ®µ3ï¼šå¼•å…¥åä½œä»»åŠ¡ & åè®®æ‰©å±•

- [ ] å®ç°éœ€è¦ä¸¤ä¸ªæˆ–å¤šä¸ªAgentååŒå®Œæˆçš„ä»»åŠ¡ç±»å‹ï¼›
- [ ] æ‰©å±•é€šä¿¡åè®®ï¼Œæ”¯æŒ `request_assist`ã€`ack_assist`ã€`sync_start` ç­‰æ¶ˆæ¯ç±»å‹ï¼›
- [ ] æ”¯æŒAgentä¹‹é—´çš„ä»»åŠ¡ç­‰å¾…ã€åŒæ­¥å¯åŠ¨ä¸è”åˆæ‰§è¡Œé€»è¾‘ï¼›
- [ ] **è¿ç§»å½“å‰ç³»ç»Ÿè‡³æ›´é€‚åˆå¤æ‚åä½œä»»åŠ¡çš„è™šæ‹Ÿç¯å¢ƒ**ï¼ˆå¦‚ Isaac Lab æˆ– PettingZooï¼‰ï¼Œå¹¶ä¿ç•™å½“å‰ç»“æ„åŒ–åè®®ä¸ç­–ç•¥æ¥å£ï¼›
- [ ] ä¿æŒ MCP åè®®å’Œç­–ç•¥æ¥å£ç¯å¢ƒæ— å…³æ€§ï¼ˆå®ç°ç¯å¢ƒæŠ½è±¡æ¥å£å°è£…ï¼‰ï¼›

### ğŸ§  é˜¶æ®µ4ï¼šæ¥å…¥å­¦ä¹ å‹ç­–ç•¥å¹¶è¿›è¡Œæ€§èƒ½è¯„ä¼°

- [ ] æ¥å…¥ PPO ç­‰å¼ºåŒ–å­¦ä¹ ç­–ç•¥ï¼ˆé€šä¿¡æ„ŸçŸ¥å†³ç­–ï¼‰ï¼›
- [ ] å¯¹æ¯” Rule-based / DP / PPO åœ¨ä¸åŒä»»åŠ¡ä¸‹çš„è¡¨ç°ï¼›
- [ ] è®¾è®¡ä»»åŠ¡å¤æ‚åº¦é€’å¢çš„æµ‹è¯•ç¯å¢ƒï¼Œé€æ­¥éªŒè¯ç³»ç»Ÿæ€§èƒ½æ‰©å±•æ€§ä¸ç­–ç•¥åä½œèƒ½åŠ›ï¼›

### ğŸŒ é˜¶æ®µ5ï¼šç³»ç»Ÿç¨³å®šæ€§æµ‹è¯• & é«˜å¤æ‚åº¦åä½œåœºæ™¯æ‰©å±•

- [ ] å¤šä»»åŠ¡å¹¶è¡Œï¼ˆå¤šä¸ªagent + å¤šç§ä»»åŠ¡åŒæ—¶è¿›è¡Œï¼‰ï¼›
- [ ] Agentèƒ½åŠ›å¼‚æ„ï¼ˆä¸åŒé€Ÿåº¦ã€å¯è¾¾æ€§ã€ç­–ç•¥ç»„åˆï¼‰ï¼›
- [ ] å¼•å…¥ä»»åŠ¡è°ƒåº¦è§„åˆ™ï¼ˆå¦‚deadlineã€æˆæœ¬æƒé‡ï¼‰ï¼›
- [ ] ç³»ç»Ÿçº§æŒ‡æ ‡è¯„ä¼°ï¼ˆæˆåŠŸç‡ã€ä»»åŠ¡æ•ˆç‡ã€é€šä¿¡å¼€é”€ï¼‰ï¼›
- [ ] å¯è§†åŒ–åä½œè¡Œä¸ºä¸é€šä¿¡æµç¨‹å›¾ï¼Œç”¨äºåç»­å±•ç¤ºä¸åˆ†æã€‚

---

## ğŸ“‚ é¡¹ç›®ç›®å½•ç»“æ„ï¼ˆå»ºè®®ï¼‰

multi_agent_mpd/
â”œâ”€â”€ main.py # Entry point: launches simulation
â”œâ”€â”€ agent.py # Agent logic (communication + strategy)
â”œâ”€â”€ protocol.py # MCP protocol structure & message handling
â”œâ”€â”€ policy.py # Policy switch logic (rule-based, DP wrapper, etc.)
â”œâ”€â”€ task_conflict_gen.py # Task assignment and conflict generation
â”œâ”€â”€ strategy/ # Additional policy wrappers & tests
â”‚ â”œâ”€â”€ dp_wrapper.py
â”‚ â””â”€â”€ test_dp_wrapper.py
â”œâ”€â”€ tools/
â”‚ â””â”€â”€ data_collector.py # Data recording / test scripts
â”œâ”€â”€ logs/ # Experiment notes & logs
â”‚ â””â”€â”€ 2025-06-25-exp1.md
â”œâ”€â”€ pybullet_log.txt # Output log (optional)
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ readme.md # Project overview (this file)

Diffusion Policy repository (as submodule or separate folder)

â”œâ”€â”€ dp_repo/ # Official DP codebase
â”‚ â”œâ”€â”€ diffusion_policy/ # Model, training, evaluation
â”‚ â”œâ”€â”€ train.py / eval.py # Training and testing scripts
â”‚ â”œâ”€â”€ outputs/ / media/ # Saved models and visual logs
â”‚ â””â”€â”€ ... # Additional DP files

Data & environment

â”œâ”€â”€ data/ # Collected trajectories, training logs
â”‚ â””â”€â”€ collected_trajs/
â”œâ”€â”€ venv_mpd/ # Local virtual environment (excluded in version control)

---

## ğŸ“ é™„ï¼šä½¿ç”¨å»ºè®®

- å¯åŠ¨ä¸»ç¨‹åºï¼š`python main.py`ï¼Œè¿è¡Œæ¨¡æ‹Ÿå¹¶è§‚å¯Ÿè¡Œä¸º
- ä¿®æ”¹Agentç­–ç•¥ï¼šåœ¨ `main.py` ä¸­é…ç½® `agent.policy = ...`
- è°ƒè¯•ä¿¡æ¯å¼€å¯ï¼šåœ¨å„æ¨¡å—ä¸­åŠ å…¥æ—¥å¿—è¾“å‡ºæˆ–æŸ¥çœ‹`print()`ä¿¡æ¯
- ç­–ç•¥å¼€å‘ï¼šç»§æ‰¿ `BasePolicy` å¹¶å®ç° `compute_action()` æ–¹æ³•

---
# ğŸ§  MCP-MAS: Modular Communication Protocol for Multi-Agent Systems

## ğŸ“Œ Project Overview

This project aims to build a **decentralized multi-agent system framework** in which each agent is fully autonomous and capable of decision-making and task execution. Through a structured communication protocol (Modular Communication Protocol, MCP), agents coordinate task allocation, conflict resolution, and cooperative execution â€” all without any centralized controller.

The system supports plug-and-play policies (e.g., Rule-based, PPO, Diffusion Policy) and enables flexible agent behaviors through message-driven coordination, making it suitable for research in distributed robotics, collaborative AI, and communication-based planning.

---

## âœ… Current Features

- **Multi-Agent Operation**: Supports 3 simultaneous agents, each capable of observation, communication, decision-making, and movement;
- **Task Environment**: Multiple target objects randomly initialized; agents autonomously claim and execute tasks through communication;
- **Structured Communication Protocol (MCP)**:
  - Supports structured messages: `claim`, `respond`, `retry`, and priority-based resolution;
  - All messages are handled via a unified protocol module (`protocol.py`);
- **Modular Policy Interface**:
  - Unified API `compute_action(obs, messages)` for all policies;
  - Integrated: `NearestTaskPolicy`, `RuleBasedPolicy`, `DiffusionPolicyWrapperAdapter`;
- **Simulation Environment**:
  - Lightweight simulation using PyBullet;
  - Agent and task initialization randomized;
- **Real-time Visualization**: Agentsâ€™ behaviors are rendered in PyBullet GUI for debugging and demonstration.

---

## ğŸš§ Current Development Status (as of June 2025)

| Module | Status | Notes |
|--------|--------|-------|
| MCP Protocol | âœ… Completed, supports multi-round negotiation and resolution |
| Multi-Agent Integration | âœ… 3 agents running stably with full autonomy |
| Policy Interface | âœ… Unified and plug-and-play for various strategies |
| Diffusion Policy Integration | âœ… Wrapper completed, stub version running |
| Environment | âœ… PyBullet-based, stable and modular |
| Behavior Bug Fix | ğŸŸ¡ Diagnosed issue: target position not correctly set; pending verification |
| Documentation | âœ… Current README + development roadmap finalized |

---

## ğŸ“ˆ Upcoming Development Plan

### ğŸ”„ Phase 3: Cooperative Tasks & Protocol Extension

- [ ] Introduce cooperative task types requiring multiple agents to succeed;
- [ ] Extend MCP to support new message types: `request_assist`, `ack_assist`, `sync_start`;
- [ ] Implement synchronization and cooperative behavior primitives (e.g., wait, joint move);
- [ ] **Migrate the project to a more advanced simulation environment** (e.g., Isaac Lab or PettingZoo) to support complex cooperative scenarios;
- [ ] Abstract simulation environment interface to keep MCP & policy components environment-agnostic;

### ğŸ§  Phase 4: Communication-Aware Learning Strategies

- [ ] Integrate PPO and other RL algorithms with message-based observation;
- [ ] Compare rule-based vs learned policies (e.g., PPO, DP) in cooperative settings;
- [ ] Design diverse task scenarios to benchmark system performance and robustness;

### ğŸŒ Phase 5: Scalability, Robustness & Complex Scenarios

- [ ] Support concurrent multi-task execution (more agents, more task types);
- [ ] Introduce agent heterogeneity (e.g., speed, capabilities, policy type);
- [ ] Add task constraints: deadlines, priorities, costs;
- [ ] System-wide evaluation: success rate, task throughput, communication overhead;
- [ ] Visualize agent trajectories, communication flows, and task coordination.

---

## ğŸ“‚ Project Structure

multi_agent_mpd/
â”œâ”€â”€ main.py # Entry point: launches simulation
â”œâ”€â”€ agent.py # Agent logic (communication + strategy)
â”œâ”€â”€ protocol.py # MCP protocol structure & message handling
â”œâ”€â”€ policy.py # Policy switch logic (rule-based, DP wrapper, etc.)
â”œâ”€â”€ task_conflict_gen.py # Task assignment and conflict generation
â”œâ”€â”€ strategy/ # Additional policy wrappers & tests
â”‚ â”œâ”€â”€ dp_wrapper.py
â”‚ â””â”€â”€ test_dp_wrapper.py
â”œâ”€â”€ tools/
â”‚ â””â”€â”€ data_collector.py # Data recording / test scripts
â”œâ”€â”€ logs/ # Experiment notes & logs
â”‚ â””â”€â”€ 2025-06-25-exp1.md
â”œâ”€â”€ pybullet_log.txt # Output log (optional)
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ readme.md # Project overview (this file)

Diffusion Policy repository (as submodule or separate folder)

â”œâ”€â”€ dp_repo/ # Official DP codebase
â”‚ â”œâ”€â”€ diffusion_policy/ # Model, training, evaluation
â”‚ â”œâ”€â”€ train.py / eval.py # Training and testing scripts
â”‚ â”œâ”€â”€ outputs/ / media/ # Saved models and visual logs
â”‚ â””â”€â”€ ... # Additional DP files

Data & environment

â”œâ”€â”€ data/ # Collected trajectories, training logs
â”‚ â””â”€â”€ collected_trajs/
â”œâ”€â”€ venv_mpd/ # Local virtual environment (excluded in version control)
---

## ğŸ“ Usage Guide

- Run simulation: `python main.py`
- Set agent policy: assign in `main.py`, e.g., `agent.policy = NearestTaskPolicy(...)`
- Debugging: enable `print()` logs in relevant modules for inspection
- Add new policy: implement subclass of `BasePolicy` with `compute_action()` method

---

This project is actively evolving. The next step is to expand to cooperative task execution and transition to a more complex environment with enhanced communication and strategy capabilities.
